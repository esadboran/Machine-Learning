{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a11c3a-52cc-436c-b5dd-b7c71c306dc9",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "<style>\n",
    "* {\n",
    "  box-sizing: border-box;\n",
    "}\n",
    "\n",
    ".row {\n",
    "  margin-left:-5px;\n",
    "  margin-right:-5px;\n",
    "}\n",
    "  \n",
    ".column {\n",
    "  float: left;\n",
    "  width: 50%;\n",
    "  padding: 5px;\n",
    "}\n",
    "\n",
    "/* Clearfix (clear floats) */\n",
    ".row::after {\n",
    "  content: \"\";\n",
    "  clear: both;\n",
    "  display: table;\n",
    "}\n",
    "\n",
    "table {\n",
    "  border-collapse: collapse;\n",
    "  border-spacing: 0;\n",
    "  width: 100%;\n",
    "  border: 1px solid #ddd;\n",
    "}\n",
    "\n",
    "th, td {\n",
    "  text-align: left;\n",
    "  padding: 16px;\n",
    "}\n",
    "\n",
    "tr:nth-child(even) {\n",
    "  background-color: #f2f2f2;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h2 style=\"text-align: center\" >BBM409 : Introduction to Machine Learning Lab.</h2>\n",
    "<h4 style=\"text-align: center\">Assignment 3 :  Naive Bayes Algorithm</h4>\n",
    "<br>\n",
    "<div class=\"row\">\n",
    "  <div class=\"column\">\n",
    "    <table>\n",
    "      <tr>\n",
    "        <th>First Name</th>\n",
    "        <th>Last Name</th>\n",
    "        <th>No</th>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Esad </td>\n",
    "        <td>Boran</td>\n",
    "        <td>21827206</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td>Evren</td>\n",
    "        <td>Çağılcı</td>\n",
    "        <td>21945977</td>\n",
    "      </tr>\n",
    "    </table>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5926fd",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53f066d",
   "metadata": {},
   "source": [
    "In this assignment, our aim is to predict which of the 5 categories the given texts belongs to.\n",
    "\n",
    "To predict the categories, Naive Bayes Classifier will be used. We will generate 4 different models to make predictions. We will genarete unigram and bigram models with and without stop words.\n",
    "\n",
    "Unigram models deal with all words one by one, while bigram models deal with words in pairs.\n",
    "\n",
    "After building our models and predicting the categories, we will calculate the accuracy, precision, recall and F1 score ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fcc87f-990b-4cc0-a967-95d1661ff8e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1.Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb07bc1",
   "metadata": {},
   "source": [
    "Here we are importing necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ee5129-26e5-4ccb-a5ca-31c9021480ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer \n",
    "\n",
    "import string\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, recall_score,precision_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9632f778-6b36-4697-a75d-28b07445b393",
   "metadata": {},
   "source": [
    "## Part I: Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c67172f",
   "metadata": {},
   "source": [
    "We read the data with pandas library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbc68ca9-e0c8-47c4-a2cf-1379a222448a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"English Dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d8e69",
   "metadata": {},
   "source": [
    "We check how many unique categories there are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cebebe0-7a8c-4c23-bd57-3ab9382d3abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business', 'tech', 'politics', 'sport', 'entertainment'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8436219",
   "metadata": {},
   "source": [
    "We group the data according the 'Category' column and check how many data there are from each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bb9434a-6ce5-407b-b15d-8f0c4251a322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "business         336.0\n",
       "entertainment    273.0\n",
       "politics         274.0\n",
       "sport            346.0\n",
       "tech             261.0\n",
       "Name: (ArticleId, count), dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('Category').describe().iloc[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee35126-bc9a-4bd8-8ae6-ab007d2d4f52",
   "metadata": {},
   "source": [
    "This method we created returns a list, which we’ll assign to a new column called tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53602247-cca4-4193-99c4-0483df2175a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>[worldcom, launches, defence, lawyers, defendi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>[german, business, confidence, slides, german,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>[bbc, poll, indicates, economic, gloom, citize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>[lifestyle, governs, mobile, choice, faster, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>[enron, bosses, in, payout, eighteen, former, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  worldcom ex-boss launches defence lawyers defe...   \n",
       "1  german business confidence slides german busin...   \n",
       "2  bbc poll indicates economic gloom citizens in ...   \n",
       "3  lifestyle  governs mobile choice  faster  bett...   \n",
       "4  enron bosses in $168m payout eighteen former e...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [worldcom, launches, defence, lawyers, defendi...  \n",
       "1  [german, business, confidence, slides, german,...  \n",
       "2  [bbc, poll, indicates, economic, gloom, citize...  \n",
       "3  [lifestyle, governs, mobile, choice, faster, b...  \n",
       "4  [enron, bosses, in, payout, eighteen, former, ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tokenized'] = data.apply(lambda x: [w for w in nltk.word_tokenize(x[\"Text\"]) if w.isalpha()]  , axis=1)\n",
    "data[['Text', 'tokenized']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5464d7b",
   "metadata": {},
   "source": [
    "We remove stop words from 'tokenized' class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b108df-b06d-4afa-9df8-b6c6efd419b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>[worldcom, launches, defence, lawyers, defendi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>[german, business, confidence, slides, german,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>[bbc, poll, indicates, economic, gloom, citize...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>[lifestyle, governs, mobile, choice, faster, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>[enron, bosses, payout, eighteen, former, enro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  worldcom ex-boss launches defence lawyers defe...   \n",
       "1  german business confidence slides german busin...   \n",
       "2  bbc poll indicates economic gloom citizens in ...   \n",
       "3  lifestyle  governs mobile choice  faster  bett...   \n",
       "4  enron bosses in $168m payout eighteen former e...   \n",
       "\n",
       "                                   stopwords_removed  \n",
       "0  [worldcom, launches, defence, lawyers, defendi...  \n",
       "1  [german, business, confidence, slides, german,...  \n",
       "2  [bbc, poll, indicates, economic, gloom, citize...  \n",
       "3  [lifestyle, governs, mobile, choice, faster, b...  \n",
       "4  [enron, bosses, payout, eighteen, former, enro...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['stopwords_removed'] = data.apply(lambda x: [word for word in x['tokenized'] if not word in set(stopwords.words(\"english\"))] , axis=1)\n",
    "data[['Text', 'stopwords_removed']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e5eab",
   "metadata": {},
   "source": [
    "We remove the morphological and inflectional endings from words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "252d4bdd-8a9b-41ef-94a7-e7cd2cafa260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>porter_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>[worldcom, launch, defenc, lawyer, defend, for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>[german, busi, confid, slide, german, busi, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>[bbc, poll, indic, econom, gloom, citizen, maj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>[lifestyl, govern, mobil, choic, faster, bette...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>[enron, boss, payout, eighteen, former, enron,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  worldcom ex-boss launches defence lawyers defe...   \n",
       "1  german business confidence slides german busin...   \n",
       "2  bbc poll indicates economic gloom citizens in ...   \n",
       "3  lifestyle  governs mobile choice  faster  bett...   \n",
       "4  enron bosses in $168m payout eighteen former e...   \n",
       "\n",
       "                                      porter_stemmed  \n",
       "0  [worldcom, launch, defenc, lawyer, defend, for...  \n",
       "1  [german, busi, confid, slide, german, busi, co...  \n",
       "2  [bbc, poll, indic, econom, gloom, citizen, maj...  \n",
       "3  [lifestyl, govern, mobil, choic, faster, bette...  \n",
       "4  [enron, boss, payout, eighteen, former, enron,...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['porter_stemmed'] = data.apply(lambda x: [PorterStemmer().stem(word) for word in x['stopwords_removed']], axis=1)\n",
    "data[['Text', 'porter_stemmed']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5492cc3",
   "metadata": {},
   "source": [
    "We have edited the text by converting the last list we have obtained back into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e86c17-7356-4d41-b559-b47e591dda31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>worldcom launch defenc lawyer defend former wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>german busi confid slide german busi confid fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>bbc poll indic econom gloom citizen major nati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>lifestyl govern mobil choic faster better funk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>enron boss payout eighteen former enron direct...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  worldcom ex-boss launches defence lawyers defe...   \n",
       "1  german business confidence slides german busin...   \n",
       "2  bbc poll indicates economic gloom citizens in ...   \n",
       "3  lifestyle  governs mobile choice  faster  bett...   \n",
       "4  enron bosses in $168m payout eighteen former e...   \n",
       "\n",
       "                                          Clear_text  \n",
       "0  worldcom launch defenc lawyer defend former wo...  \n",
       "1  german busi confid slide german busi confid fe...  \n",
       "2  bbc poll indic econom gloom citizen major nati...  \n",
       "3  lifestyl govern mobil choic faster better funk...  \n",
       "4  enron boss payout eighteen former enron direct...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Clear_text'] = data.apply(lambda x: ( \" \".join(x['porter_stemmed'])), axis=1)\n",
    "data[['Text', 'Clear_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90832695-01f9-4714-ace8-1a721da38419",
   "metadata": {},
   "source": [
    "#  Spesific Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7921d601-9ac1-4163-9e57-e09376018752",
   "metadata": {},
   "source": [
    "According to the words found in our classes, we looked at the 3 most common words in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c0fde0e-82c0-43b3-944b-0d76ffdc1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6e61fc1-527d-4e31-b097-cde9a8aea9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Business</th>\n",
       "      <th>Count Business</th>\n",
       "      <th>Tech</th>\n",
       "      <th>Count Tech</th>\n",
       "      <th>Politics</th>\n",
       "      <th>Count Politics</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Count Sport</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Count Entertainment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Said</td>\n",
       "      <td>1100</td>\n",
       "      <td>Said</td>\n",
       "      <td>1064</td>\n",
       "      <td>Said</td>\n",
       "      <td>1445</td>\n",
       "      <td>Said</td>\n",
       "      <td>635</td>\n",
       "      <td>Film</td>\n",
       "      <td>706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Year</td>\n",
       "      <td>574</td>\n",
       "      <td>Use</td>\n",
       "      <td>662</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1099</td>\n",
       "      <td>Game</td>\n",
       "      <td>482</td>\n",
       "      <td>Said</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr</td>\n",
       "      <td>394</td>\n",
       "      <td>Peopl</td>\n",
       "      <td>646</td>\n",
       "      <td>Labour</td>\n",
       "      <td>488</td>\n",
       "      <td>Win</td>\n",
       "      <td>419</td>\n",
       "      <td>Best</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Business  Count Business   Tech  Count Tech Politics  Count Politics Sport  \\\n",
       "0     Said            1100   Said        1064     Said            1445  Said   \n",
       "1     Year             574    Use         662       Mr            1099  Game   \n",
       "2       Mr             394  Peopl         646   Labour             488   Win   \n",
       "\n",
       "   Count Sport Entertainment  Count Entertainment  \n",
       "0          635          Film                  706  \n",
       "1          482          Said                  594  \n",
       "2          419          Best                  404  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spesific_keywords_df = pd.DataFrame()\n",
    "for i in data.Category.unique():\n",
    "    keyword_list = list()\n",
    "    data_category = data[data.Category == i]\n",
    "    X_category = vectorizer.fit_transform(data_category.Clear_text)\n",
    "    words_count = np.sum(X_category.toarray(), axis=0)\n",
    "    words_total = words_count.sum()\n",
    "    freq_of_words = dict(zip(vectorizer.get_feature_names_out(), words_count))\n",
    "    freq_of_words = dict(sorted(freq_of_words.items(), key=lambda item: item[1], reverse=True))\n",
    "    \n",
    "    \n",
    "    \n",
    "    spesific_keywords_list = list()\n",
    "    spesific_keywords_count = list()\n",
    "    \n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for item in freq_of_words.items():\n",
    "        count += 1\n",
    "        #print(\" Catogery : \",i,\" İtem --> \",item[0], \" Count--> \", item[1])\n",
    "        spesific_keywords_list.append(item[0].capitalize())\n",
    "        spesific_keywords_count.append(item[1])\n",
    "        if count == 3:  # Whichever number you write instead of 3 will return as many words\n",
    "            break\n",
    "            \n",
    "    c_name = i.capitalize()\n",
    "    spesific_keywords_df[c_name] = spesific_keywords_list\n",
    "    c_name = \"Count \" + i.capitalize()\n",
    "    spesific_keywords_df[c_name] = spesific_keywords_count\n",
    "    \n",
    "    \n",
    "    \n",
    "       \n",
    "spesific_keywords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ff725f-3bad-4926-9d94-ffe58f232109",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part2 : Gaussian Naive Bayes"
   ]
  },
  {
   "attachments": {
    "Naive_Bayes_Formula.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "9dbe7aef",
   "metadata": {},
   "source": [
    "Gaussian Naive Bayes is a variant of Naive Bayes algorithm.\n",
    "Here is Naive Bayes formula :\n",
    "<img src=\"attachment:Naive_Bayes_Formula.png\" width=\"300\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d7e6900-cacd-4ea8-ae96-ca2809173189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class GaussianNaiveBayes:\n",
    "    alpha = None\n",
    "    prop_classes = {}\n",
    "    idx_classes = defaultdict() \n",
    "    num_of_words_classes = defaultdict()\n",
    "    each_class_vectorizer = defaultdict()\n",
    "    prop_each_classes_word = defaultdict()\n",
    "    classes = None # y_train.unique()\n",
    "    n_gram = None\n",
    "    \n",
    "    \n",
    "    def __init__(self,n_gram):\n",
    "        self.alpha = 1\n",
    "        self.n_gram = n_gram\n",
    "        \n",
    "    def fit(self, X_train,y_train):\n",
    "        \n",
    "        self.words = X_train[\"words\"]                            # list of all words in data\n",
    "        self.classes = y_train.unique()\n",
    "        num_of_distinct_words = len(self.words)                  # number of all words\n",
    "        matrix_vectorizer_X_train = X_train[\"vectorizer\"]        # vectorizer matrix\n",
    "       \n",
    "        self.prop_classes = dict(y_train.value_counts()/len(y_train))  # Oranların listesi\n",
    "        \n",
    "        for i in self.classes:\n",
    "            idx  = y_train[y_train == i].index\n",
    "            self.idx_classes[i] = idx                         # İndexlerin Sınıflara ayrılmış Listesi\n",
    "       \n",
    "       \n",
    "       \n",
    "        for i in self.classes:\n",
    "            idx = self.idx_classes[i]\n",
    "            count = 0\n",
    "            for j in idx:\n",
    "                count += np.sum(matrix_vectorizer_X_train.iloc[j])\n",
    "                \n",
    "            self.num_of_words_classes[i] = count  #'sport': 48222, 'business': 48503, 'politics': 49348, 'entertainment': 41560, 'tech': 53636}\n",
    "        \n",
    "        \n",
    "        \n",
    "   \n",
    "        \n",
    "        for i in self.classes:\n",
    "            idx = self.idx_classes[i]\n",
    "            each_class = matrix_vectorizer_X_train.iloc[idx]\n",
    "            self.each_class_vectorizer[i] = each_class      #'sport': sport_vectorizer, 'business': business_vectorizer, ....... 'tech': tech_vectorizer}\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in self.classes:\n",
    "            prop_each_classes_word = {word:0 for word in self.words}\n",
    "            self.prop_each_classes_word[i] = prop_each_classes_word  # sport': sport_word_prob, ......  'tech': tech_word_prob}\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        for word in self.words:\n",
    "            for i in self.classes: \n",
    "                num_of_word_given_i = self.each_class_vectorizer[i][word].sum()\n",
    "                prob_word_given_i = (num_of_word_given_i + self.alpha) / ( self.num_of_words_classes[i] + self.alpha * num_of_distinct_words)\n",
    "                self.prop_each_classes_word[i][word] = prob_word_given_i\n",
    "                \n",
    "                \n",
    "                \n",
    "        \n",
    "    def predict(self,X_test):        \n",
    "        y_pred = list()        \n",
    "    \n",
    "    \n",
    "        for element in X_test:\n",
    "            \n",
    "            p_each_class= defaultdict()\n",
    "            \n",
    "            if self.n_gram == \"unigram\":  \n",
    "                list_of_instance_sentence = element.split(' ')\n",
    "            elif self.n_gram == \"bigram\":\n",
    "                words = element.split(\" \")\n",
    "                list_of_instance_sentence = []\n",
    "                for i in range(0, len(words) - 1, 2):\n",
    "                    pair = [words[i], words[i + 1]]\n",
    "                    list_of_instance_sentence.append(pair)\n",
    "          \n",
    "            for i in self.classes:\n",
    "                p_each = np.log(self.prop_classes[i])\n",
    "                for word in list_of_instance_sentence:\n",
    "                    if self.n_gram == \"bigram\":\n",
    "                        word  = \" \".join(word)\n",
    "                    if word in  self.prop_each_classes_word[i]:\n",
    "                        p_each += np.log(self.prop_each_classes_word[i][word])\n",
    "                p_each_class[i] = p_each\n",
    "                \n",
    "        \n",
    "            pred = max(p_each_class.items(), key=lambda a: a[1])[0]\n",
    "            y_pred.append(pred)\n",
    "                  \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaf0dc4",
   "metadata": {},
   "source": [
    "We seperate the data with the ratio of 80/20 to generate X_train, X_test, y_train and y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73061bbe-9c5f-46dd-a6c6-3a62e1afb19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"Text\"], data[\"Category\"], test_size=0.20, random_state=42)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad52d3",
   "metadata": {},
   "source": [
    "The prepare_X_train function arranges the X_train method to be used  Naive Bayes code according to the ngram_range and stop words we want\n",
    "\n",
    "If ngram_range is (1,1), it means that X_train is unigram. \n",
    "\n",
    "Else ngram_range is(2,2), it means that X_train is bigram. \n",
    "\n",
    "If stop_words is none, then we dont remove stop words from X_train. \n",
    "\n",
    "Else stop_words is 'english', then we remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc000513-4c81-4d50-9fbf-5115c15896e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X_train(X_train, ngram_range ,stop_words):\n",
    "    vectorizer = CountVectorizer(ngram_range=ngram_range, stop_words=stop_words) # obtain BoW model (two option : bigram(2,2), unigram(1,1))\n",
    "    matrix_vectorize = vectorizer.fit_transform(X_train)\n",
    "    words_X_train = list(vectorizer.get_feature_names_out())\n",
    "    matrix_vectorizer_X_train = pd.DataFrame(matrix_vectorize.toarray(), columns = list(words_X_train))\n",
    "    X_train = {\"words\": words_X_train, \"vectorizer\" :matrix_vectorizer_X_train }\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97dc206-c21c-4323-8289-5f31e8f1b707",
   "metadata": {},
   "source": [
    "## Unigram without removing stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bddbcb6",
   "metadata": {},
   "source": [
    "Here, we train our unigram model without removing stopwords from X_train.\n",
    "\n",
    "Then we calculate the model's accuracy, precision, recall and f1 score values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7acc7ce-1f3f-46d4-9d5f-a7a2557fd529",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9731543624161074\n",
      "Precision:  0.9738560193587418\n",
      "Recall:  0.9728311558506462\n",
      "F1 Score:  0.9732468965054778\n"
     ]
    }
   ],
   "source": [
    "X_train_unigram_without_stop_words = prepare_X_train(X_train,(1,1),stop_words= None)\n",
    "\n",
    "model = GaussianNaiveBayes(n_gram=\"unigram\")\n",
    "\n",
    "model.fit(X_train_unigram_without_stop_words,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision: \",precision_score(y_test,y_pred,average=\"macro\"))\n",
    "print(\"Recall: \" ,recall_score(y_test,y_pred,average=\"macro\"))\n",
    "print(\"F1 Score: \", f1_score(y_test,y_pred,average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a471a7b-7fca-47b2-a573-ed24285a8134",
   "metadata": {},
   "source": [
    "## Unigram with removing stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1e8fdb",
   "metadata": {},
   "source": [
    "Here, we train our unigram model with removing stopwords from X_train.\n",
    "\n",
    "Then we calculate the model's accuracy, precision, recall and f1 score values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3151c7f3-9bb7-4a0b-b333-4cc82f9be7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9765100671140939\n",
      "Precision:  0.977243799153055\n",
      "Recall:  0.976279431712715\n",
      "F1 Score:  0.9767227552226027\n"
     ]
    }
   ],
   "source": [
    "X_train_unigram_with_stop_words = prepare_X_train(X_train,(1,1),stop_words= \"english\")\n",
    "\n",
    "model = GaussianNaiveBayes(n_gram=\"unigram\")\n",
    "\n",
    "model.fit(X_train_unigram_with_stop_words,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision: \",precision_score(y_test,y_pred,average=\"macro\"))\n",
    "print(\"Recall: \" ,recall_score(y_test,y_pred,average=\"macro\"))\n",
    "print(\"F1 Score: \", f1_score(y_test,y_pred,average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f232c0f5-57d6-4b3a-90e1-96d744642b6f",
   "metadata": {},
   "source": [
    "## Bigram without removing stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e03115",
   "metadata": {},
   "source": [
    "Here, we train our bigram model without removing stopwords from X_train.\n",
    "\n",
    "Then we calculate the model's accuracy, precision, recall and f1 score values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89216948-c252-4fa0-9040-11d0c83ae3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9463087248322147\n",
      "Precision:  0.9497162294566766\n",
      "Recall:  0.9424335689298209\n",
      "F1 Score:  0.9441044114249373\n"
     ]
    }
   ],
   "source": [
    "X_train_biagram_without_stop_words = prepare_X_train(X_train,(2,2),stop_words= None)\n",
    "\n",
    "model = GaussianNaiveBayes(n_gram=\"bigram\")\n",
    "\n",
    "model.fit(X_train_biagram_without_stop_words,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision: \",precision_score(y_test,y_pred,average=\"macro\"))\n",
    "print(\"Recall: \" ,recall_score(y_test,y_pred,average=\"macro\"))\n",
    "print(\"F1 Score: \", f1_score(y_test,y_pred,average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a4ce13-7bf7-40c8-9b02-146d01882560",
   "metadata": {},
   "source": [
    "## Bigram with removing stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b92ae2",
   "metadata": {},
   "source": [
    "Here, we train our bigram model with removing stopwords from X_train.\n",
    "\n",
    "Then we calculate the model's accuracy, precision, recall and f1 score values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "188cc730-12fc-486d-83e0-0b5973937ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9463087248322147\n",
      "Precision:  0.9470623418449506\n",
      "Recall:  0.9468579995716426\n",
      "F1 Score:  0.9464885414435639\n"
     ]
    }
   ],
   "source": [
    "X_train_biagram_with_stop_words = prepare_X_train(X_train,(2,2),stop_words= \"english\")\n",
    "\n",
    "model = GaussianNaiveBayes(n_gram=\"bigram\")\n",
    "\n",
    "model.fit(X_train_biagram_with_stop_words,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: \",accuracy_score(y_test,y_pred))\n",
    "print(\"Precision: \",precision_score(y_test,y_pred,average=\"macro\"))\n",
    "print(\"Recall: \" ,recall_score(y_test,y_pred,average=\"macro\"))\n",
    "print(\"F1 Score: \", f1_score(y_test,y_pred,average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90299e29-a7d5-40bb-88a2-b152fb0f071c",
   "metadata": {},
   "source": [
    "# Part 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5695649a-ea38-4dbe-aa07-150fd8daac88",
   "metadata": {},
   "source": [
    "## 3.1 Analyzing effect of the words on prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d1ceaf",
   "metadata": {},
   "source": [
    "get_frequency_data function calculates the frequencies of the words for each unique categories with using tf-idf algorithm.\n",
    "\n",
    "frequency_presence is a list that keeps most common words appeared in each unique categories.\n",
    "\n",
    "frequency_absence is a list that keeps least common words appeared in each unique categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d227d75a-0ba8-4963-a74c-d4350a087558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_data(x, stop_value=None):\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,1), stop_words=stop_value)\n",
    "    matrix_vectorize = vectorizer.fit_transform(x)\n",
    "    words = list(vectorizer.get_feature_names_out())\n",
    "    tf_idf = TfidfTransformer()\n",
    "    words_tf_tdf = tf_idf.fit(matrix_vectorize).idf_\n",
    "    frequency = dict(zip(words, words_tf_tdf))\n",
    "    frequency = dict(sorted(frequency.items(), key=lambda item: item[1]))\n",
    "    return frequency  # frequency based calculation with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c794409-e9f7-4091-928c-3537c4cd343d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frequency_presence = defaultdict()\n",
    "frequency_absence = defaultdict()\n",
    "for i in data.Category.unique():\n",
    "    frequency_class = get_frequency_data(data[data.Category == i].Text)\n",
    "    frequency_presence[i] = list(frequency_class.items())[:10]\n",
    "    frequency_absence[i] = list(frequency_class.items())[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bca69d",
   "metadata": {},
   "source": [
    "Below is 10 words whose presence most strongly predicts that the article belongs to specific category for each five categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a823e1fa-0b36-424e-a707-b2eb1da4d509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>tech</th>\n",
       "      <th>politics</th>\n",
       "      <th>sport</th>\n",
       "      <th>entertainment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(of, 1.0)</td>\n",
       "      <td>(and, 1.0)</td>\n",
       "      <td>(in, 1.0)</td>\n",
       "      <td>(the, 1.0)</td>\n",
       "      <td>(the, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(the, 1.0)</td>\n",
       "      <td>(the, 1.0)</td>\n",
       "      <td>(the, 1.0)</td>\n",
       "      <td>(to, 1.0028860048891348)</td>\n",
       "      <td>(in, 1.0036563112031105)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(to, 1.0)</td>\n",
       "      <td>(to, 1.0)</td>\n",
       "      <td>(to, 1.0)</td>\n",
       "      <td>(in, 1.014514042884254)</td>\n",
       "      <td>(of, 1.007326040092073)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(in, 1.0029717703891574)</td>\n",
       "      <td>(of, 1.0076628727455692)</td>\n",
       "      <td>(and, 1.0072993024816115)</td>\n",
       "      <td>(of, 1.014514042884254)</td>\n",
       "      <td>(and, 1.0110092855083694)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(and, 1.0119404403719179)</td>\n",
       "      <td>(in, 1.019268418865877)</td>\n",
       "      <td>(of, 1.0072993024816115)</td>\n",
       "      <td>(and, 1.0174423026633423)</td>\n",
       "      <td>(to, 1.018416726786231)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(said, 1.0802900181731276)</td>\n",
       "      <td>(that, 1.0270809586026706)</td>\n",
       "      <td>(on, 1.052250690343878)</td>\n",
       "      <td>(for, 1.0904230060695785)</td>\n",
       "      <td>(on, 1.0679506619085077)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(for, 1.0964978283999811)</td>\n",
       "      <td>(it, 1.0310102367425602)</td>\n",
       "      <td>(is, 1.0560894666510436)</td>\n",
       "      <td>(but, 1.1290130033394477)</td>\n",
       "      <td>(for, 1.07973861766055)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(that, 1.1229894438469572)</td>\n",
       "      <td>(is, 1.0389154162496737)</td>\n",
       "      <td>(for, 1.0599430359670337)</td>\n",
       "      <td>(on, 1.1422145151979834)</td>\n",
       "      <td>(was, 1.1837824774336294)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(it, 1.1263507915496622)</td>\n",
       "      <td>(for, 1.0428915646293129)</td>\n",
       "      <td>(be, 1.0676950127713514)</td>\n",
       "      <td>(at, 1.1623494236070395)</td>\n",
       "      <td>(has, 1.1970277041836501)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(is, 1.1365031630136802)</td>\n",
       "      <td>(be, 1.0877055804191054)</td>\n",
       "      <td>(said, 1.075507552508145)</td>\n",
       "      <td>(with, 1.1863642998109132)</td>\n",
       "      <td>(with, 1.2104507245157907)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     business                        tech  \\\n",
       "0                   (of, 1.0)                  (and, 1.0)   \n",
       "1                  (the, 1.0)                  (the, 1.0)   \n",
       "2                   (to, 1.0)                   (to, 1.0)   \n",
       "3    (in, 1.0029717703891574)    (of, 1.0076628727455692)   \n",
       "4   (and, 1.0119404403719179)     (in, 1.019268418865877)   \n",
       "5  (said, 1.0802900181731276)  (that, 1.0270809586026706)   \n",
       "6   (for, 1.0964978283999811)    (it, 1.0310102367425602)   \n",
       "7  (that, 1.1229894438469572)    (is, 1.0389154162496737)   \n",
       "8    (it, 1.1263507915496622)   (for, 1.0428915646293129)   \n",
       "9    (is, 1.1365031630136802)    (be, 1.0877055804191054)   \n",
       "\n",
       "                    politics                       sport  \\\n",
       "0                  (in, 1.0)                  (the, 1.0)   \n",
       "1                 (the, 1.0)    (to, 1.0028860048891348)   \n",
       "2                  (to, 1.0)     (in, 1.014514042884254)   \n",
       "3  (and, 1.0072993024816115)     (of, 1.014514042884254)   \n",
       "4   (of, 1.0072993024816115)   (and, 1.0174423026633423)   \n",
       "5    (on, 1.052250690343878)   (for, 1.0904230060695785)   \n",
       "6   (is, 1.0560894666510436)   (but, 1.1290130033394477)   \n",
       "7  (for, 1.0599430359670337)    (on, 1.1422145151979834)   \n",
       "8   (be, 1.0676950127713514)    (at, 1.1623494236070395)   \n",
       "9  (said, 1.075507552508145)  (with, 1.1863642998109132)   \n",
       "\n",
       "                entertainment  \n",
       "0                  (the, 1.0)  \n",
       "1    (in, 1.0036563112031105)  \n",
       "2     (of, 1.007326040092073)  \n",
       "3   (and, 1.0110092855083694)  \n",
       "4     (to, 1.018416726786231)  \n",
       "5    (on, 1.0679506619085077)  \n",
       "6     (for, 1.07973861766055)  \n",
       "7   (was, 1.1837824774336294)  \n",
       "8   (has, 1.1970277041836501)  \n",
       "9  (with, 1.2104507245157907)  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ten presence word\n",
    "tf_idf_presence_word = pd.DataFrame.from_dict(frequency_presence)\n",
    "tf_idf_presence_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6f0b4d",
   "metadata": {},
   "source": [
    "Below is 10 words whose absence most strongly predicts that the article belongs to specific category for each five categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07618ef6-36b7-4762-b746-77059ff3d1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>tech</th>\n",
       "      <th>politics</th>\n",
       "      <th>sport</th>\n",
       "      <th>entertainment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(yukon, 6.126935749792416)</td>\n",
       "      <td>(yusuf, 5.875197323201151)</td>\n",
       "      <td>(yoga, 5.923623917106626)</td>\n",
       "      <td>(zambia, 6.156177599386914)</td>\n",
       "      <td>(zephaniah, 5.919980925828125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(yulia, 6.126935749792416)</td>\n",
       "      <td>(zar, 5.875197323201151)</td>\n",
       "      <td>(yorker, 5.923623917106626)</td>\n",
       "      <td>(zara, 6.156177599386914)</td>\n",
       "      <td>(zero, 5.919980925828125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(yungmin, 6.126935749792416)</td>\n",
       "      <td>(zdnet, 5.875197323201151)</td>\n",
       "      <td>(youngster, 5.923623917106626)</td>\n",
       "      <td>(zealousness, 6.156177599386914)</td>\n",
       "      <td>(zimbabwe, 5.919980925828125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(yuri, 6.126935749792416)</td>\n",
       "      <td>(zed, 5.875197323201151)</td>\n",
       "      <td>(youngsters, 5.923623917106626)</td>\n",
       "      <td>(zheng, 6.156177599386914)</td>\n",
       "      <td>(zoe, 5.919980925828125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(yury, 6.126935749792416)</td>\n",
       "      <td>(zens, 5.875197323201151)</td>\n",
       "      <td>(yourself, 5.923623917106626)</td>\n",
       "      <td>(zib, 6.156177599386914)</td>\n",
       "      <td>(zola, 5.919980925828125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(zack, 6.126935749792416)</td>\n",
       "      <td>(zip, 5.875197323201151)</td>\n",
       "      <td>(youths, 5.923623917106626)</td>\n",
       "      <td>(ziers, 6.156177599386914)</td>\n",
       "      <td>(zombie, 5.919980925828125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(zardari, 6.126935749792416)</td>\n",
       "      <td>(zodiac, 5.875197323201151)</td>\n",
       "      <td>(yushchenko, 5.923623917106626)</td>\n",
       "      <td>(zimbabwe, 6.156177599386914)</td>\n",
       "      <td>(zone, 5.919980925828125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(zinc, 6.126935749792416)</td>\n",
       "      <td>(zombie, 5.875197323201151)</td>\n",
       "      <td>(yvette, 5.923623917106626)</td>\n",
       "      <td>(zoe, 6.156177599386914)</td>\n",
       "      <td>(zooropa, 5.919980925828125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(zoellick, 6.126935749792416)</td>\n",
       "      <td>(zonealarm, 5.875197323201151)</td>\n",
       "      <td>(zambian, 5.923623917106626)</td>\n",
       "      <td>(zola, 6.156177599386914)</td>\n",
       "      <td>(zorro, 5.919980925828125)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(zones, 6.126935749792416)</td>\n",
       "      <td>(zones, 5.875197323201151)</td>\n",
       "      <td>(zone, 5.923623917106626)</td>\n",
       "      <td>(zuluaga, 6.156177599386914)</td>\n",
       "      <td>(zutons, 5.919980925828125)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        business                            tech  \\\n",
       "0     (yukon, 6.126935749792416)      (yusuf, 5.875197323201151)   \n",
       "1     (yulia, 6.126935749792416)        (zar, 5.875197323201151)   \n",
       "2   (yungmin, 6.126935749792416)      (zdnet, 5.875197323201151)   \n",
       "3      (yuri, 6.126935749792416)        (zed, 5.875197323201151)   \n",
       "4      (yury, 6.126935749792416)       (zens, 5.875197323201151)   \n",
       "5      (zack, 6.126935749792416)        (zip, 5.875197323201151)   \n",
       "6   (zardari, 6.126935749792416)     (zodiac, 5.875197323201151)   \n",
       "7      (zinc, 6.126935749792416)     (zombie, 5.875197323201151)   \n",
       "8  (zoellick, 6.126935749792416)  (zonealarm, 5.875197323201151)   \n",
       "9     (zones, 6.126935749792416)      (zones, 5.875197323201151)   \n",
       "\n",
       "                          politics                             sport  \\\n",
       "0        (yoga, 5.923623917106626)       (zambia, 6.156177599386914)   \n",
       "1      (yorker, 5.923623917106626)         (zara, 6.156177599386914)   \n",
       "2   (youngster, 5.923623917106626)  (zealousness, 6.156177599386914)   \n",
       "3  (youngsters, 5.923623917106626)        (zheng, 6.156177599386914)   \n",
       "4    (yourself, 5.923623917106626)          (zib, 6.156177599386914)   \n",
       "5      (youths, 5.923623917106626)        (ziers, 6.156177599386914)   \n",
       "6  (yushchenko, 5.923623917106626)     (zimbabwe, 6.156177599386914)   \n",
       "7      (yvette, 5.923623917106626)          (zoe, 6.156177599386914)   \n",
       "8     (zambian, 5.923623917106626)         (zola, 6.156177599386914)   \n",
       "9        (zone, 5.923623917106626)      (zuluaga, 6.156177599386914)   \n",
       "\n",
       "                    entertainment  \n",
       "0  (zephaniah, 5.919980925828125)  \n",
       "1       (zero, 5.919980925828125)  \n",
       "2   (zimbabwe, 5.919980925828125)  \n",
       "3        (zoe, 5.919980925828125)  \n",
       "4       (zola, 5.919980925828125)  \n",
       "5     (zombie, 5.919980925828125)  \n",
       "6       (zone, 5.919980925828125)  \n",
       "7    (zooropa, 5.919980925828125)  \n",
       "8      (zorro, 5.919980925828125)  \n",
       "9     (zutons, 5.919980925828125)  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ten absence word\n",
    "tf_idf_absence_word = pd.DataFrame.from_dict(frequency_absence)\n",
    "tf_idf_absence_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e44cd",
   "metadata": {},
   "source": [
    "## 3.2 Analyzing effect of the non-stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391c7637",
   "metadata": {},
   "source": [
    "get_frequency_data_of_nonstopwords function calculates the frequencies of the words for each unique categories with removing stop words.\n",
    "\n",
    "frequency_nonstopwords is a list that keeps most common words appeared in each unique categories when we remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7af7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_data_of_nonstopwords(x, stop_value=\"english\"):\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,1), stop_words=stop_value)\n",
    "    matrix_vectorize = vectorizer.fit_transform(x)\n",
    "    words = list(vectorizer.get_feature_names_out())\n",
    "    tf_idf = TfidfTransformer()\n",
    "    words_tf_tdf = tf_idf.fit(matrix_vectorize).idf_\n",
    "    frequency = dict(zip(words, words_tf_tdf))\n",
    "    frequency = dict(sorted(frequency.items(), key=lambda item: item[1]))\n",
    "    return frequency  # frequency based calculation with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ce54f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_nonstopwords = defaultdict()\n",
    "for i in data.Category.unique():\n",
    "    frequency_class_nonstopwords = get_frequency_data_of_nonstopwords(data[data.Category == i].Text)\n",
    "    frequency_nonstopwords[i] = list(frequency_class_nonstopwords.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43077d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business</th>\n",
       "      <th>tech</th>\n",
       "      <th>politics</th>\n",
       "      <th>sport</th>\n",
       "      <th>entertainment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(said, 1.0802900181731276)</td>\n",
       "      <td>(said, 1.1259267932393033)</td>\n",
       "      <td>(said, 1.075507552508145)</td>\n",
       "      <td>(said, 1.2546134003450202)</td>\n",
       "      <td>(said, 1.2950081125438537)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(year, 1.449444902224699)</td>\n",
       "      <td>(people, 1.29534494519735)</td>\n",
       "      <td>(mr, 1.2414926899824064)</td>\n",
       "      <td>(year, 1.6182161630922725)</td>\n",
       "      <td>(year, 1.4598365118902912)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(new, 1.7962024095060853)</td>\n",
       "      <td>(new, 1.4623990298605163)</td>\n",
       "      <td>(government, 1.3964152725882464)</td>\n",
       "      <td>(time, 1.67317504737303)</td>\n",
       "      <td>(film, 1.7004732206520181)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(market, 1.8572383000924546)</td>\n",
       "      <td>(use, 1.7085320993994246)</td>\n",
       "      <td>(people, 1.5798184952529422)</td>\n",
       "      <td>(win, 1.7194260650237858)</td>\n",
       "      <td>(new, 1.776846199436592)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(company, 1.8713230399741934)</td>\n",
       "      <td>(year, 1.7163142398414797)</td>\n",
       "      <td>(minister, 1.6469577980905707)</td>\n",
       "      <td>(game, 1.8058996630276125)</td>\n",
       "      <td>(best, 1.949689012276003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(firm, 1.9148081519139324)</td>\n",
       "      <td>(technology, 1.7643234590278403)</td>\n",
       "      <td>(labour, 1.6895174125093666)</td>\n",
       "      <td>(world, 1.9440500015084297)</td>\n",
       "      <td>(star, 2.0180082562534802)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(mr, 1.9448856071512104)</td>\n",
       "      <td>(make, 1.7725539581643557)</td>\n",
       "      <td>(election, 1.7415737744654196)</td>\n",
       "      <td>(just, 1.9741274567457077)</td>\n",
       "      <td>(including, 2.113318436057805)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(chief, 2.0751508019891114)</td>\n",
       "      <td>(way, 1.7725539581643557)</td>\n",
       "      <td>(new, 1.7647408337469541)</td>\n",
       "      <td>(old, 2.0453037352136025)</td>\n",
       "      <td>(time, 2.113318436057805)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2004, 2.092695111640021)</td>\n",
       "      <td>(mr, 1.7808527609790508)</td>\n",
       "      <td>(party, 1.8045867422941537)</td>\n",
       "      <td>(won, 2.053534234350118)</td>\n",
       "      <td>(uk, 2.1244917366559304)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(years, 2.1105527290400277)</td>\n",
       "      <td>(like, 1.8061705689633407)</td>\n",
       "      <td>(told, 1.8127500529333147)</td>\n",
       "      <td>(team, 2.0702012868353297)</td>\n",
       "      <td>(years, 2.1357912919098636)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        business                              tech  \\\n",
       "0     (said, 1.0802900181731276)        (said, 1.1259267932393033)   \n",
       "1      (year, 1.449444902224699)        (people, 1.29534494519735)   \n",
       "2      (new, 1.7962024095060853)         (new, 1.4623990298605163)   \n",
       "3   (market, 1.8572383000924546)         (use, 1.7085320993994246)   \n",
       "4  (company, 1.8713230399741934)        (year, 1.7163142398414797)   \n",
       "5     (firm, 1.9148081519139324)  (technology, 1.7643234590278403)   \n",
       "6       (mr, 1.9448856071512104)        (make, 1.7725539581643557)   \n",
       "7    (chief, 2.0751508019891114)         (way, 1.7725539581643557)   \n",
       "8      (2004, 2.092695111640021)          (mr, 1.7808527609790508)   \n",
       "9    (years, 2.1105527290400277)        (like, 1.8061705689633407)   \n",
       "\n",
       "                           politics                        sport  \\\n",
       "0         (said, 1.075507552508145)   (said, 1.2546134003450202)   \n",
       "1          (mr, 1.2414926899824064)   (year, 1.6182161630922725)   \n",
       "2  (government, 1.3964152725882464)     (time, 1.67317504737303)   \n",
       "3      (people, 1.5798184952529422)    (win, 1.7194260650237858)   \n",
       "4    (minister, 1.6469577980905707)   (game, 1.8058996630276125)   \n",
       "5      (labour, 1.6895174125093666)  (world, 1.9440500015084297)   \n",
       "6    (election, 1.7415737744654196)   (just, 1.9741274567457077)   \n",
       "7         (new, 1.7647408337469541)    (old, 2.0453037352136025)   \n",
       "8       (party, 1.8045867422941537)     (won, 2.053534234350118)   \n",
       "9        (told, 1.8127500529333147)   (team, 2.0702012868353297)   \n",
       "\n",
       "                    entertainment  \n",
       "0      (said, 1.2950081125438537)  \n",
       "1      (year, 1.4598365118902912)  \n",
       "2      (film, 1.7004732206520181)  \n",
       "3        (new, 1.776846199436592)  \n",
       "4       (best, 1.949689012276003)  \n",
       "5      (star, 2.0180082562534802)  \n",
       "6  (including, 2.113318436057805)  \n",
       "7       (time, 2.113318436057805)  \n",
       "8        (uk, 2.1244917366559304)  \n",
       "9     (years, 2.1357912919098636)  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_nonstopwords = pd.DataFrame.from_dict(frequency_nonstopwords)\n",
    "tf_idf_nonstopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fbb93b-b087-4849-a7f4-fa7865d1b368",
   "metadata": {},
   "source": [
    "### 3.2.1 Analyzing effect of the stopwords:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2536fe",
   "metadata": {},
   "source": [
    "Removing stop words makes really sense because it makes our prediction more meaningful. If you analyze the table without removing stop words(\"tf_idf_presence_word\"), you can see that almost all of the outputs are consisted of stop words and this makes almost impossible to predict the category. If you analyze the table with removing the stop words(\"tf_idf_nonstopwords\"), you can see that almost all of the outputs are different for different catagories and they are meaningful. By removing stop words, every people can predict the category just for looking to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85cbb0f-9d6f-445d-8f94-30b4e5c79de7",
   "metadata": {},
   "source": [
    "# Part 4 : Conclusion \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152da247-1347-4249-b5e0-5c26711d548c",
   "metadata": {},
   "source": [
    "## 4.1 Analysis of accuracy :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3259b5bf-b90e-41f4-9b00-28e81642a97b",
   "metadata": {},
   "source": [
    "As you can see from the tables in part2, accuracy values are as fallows:\n",
    "\n",
    "Accuracy of unigram model without removing stop words : 0.9731543624161074 \n",
    "\n",
    "Accuracy of unigram model with removing stop words : 0.9765100671 140939\n",
    "\n",
    "Accuracy of bigram model without removing stop words : 0.9463087248322147\n",
    "\n",
    "Accuracy of bigram model with removing stop words : 0.9463087248322147\n",
    "\n",
    "By analyzing these values, we can say that unigram models have better accuracy values than bigram models. Also we can say that removing stop words increased the accuracy value for unigram model but it didn't make any effect on bigram models.\n",
    "\n",
    "In addition, because the bigram model takes words in pairs, it comes up with a slower algorithm compared to the unigram model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4294b9-206e-4f6b-9491-6403e43034c5",
   "metadata": {},
   "source": [
    "## 4.2 Algorithm Speed Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9826a46b-c63f-42ef-b1bf-5bb25d548390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Fit Time : 25.000730991363525\n",
      "Model Predict Time:  0.05440831184387207\n"
     ]
    }
   ],
   "source": [
    "X_train_unigram_with_stop_words = prepare_X_train(X_train,(1,1),stop_words= None)\n",
    "\n",
    "\n",
    "model = GaussianNaiveBayes(n_gram=\"unigram\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(X_train_biagram_with_stop_words,y_train)\n",
    "\n",
    "start2_time = time.time()\n",
    "\n",
    "x = start2_time - start_time\n",
    "\n",
    "print(\"Model Fit Time :\", x)\n",
    "\n",
    "start_time= time.time()\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "start2_time = time.time()\n",
    "\n",
    "x = start2_time - start_time\n",
    "\n",
    "print(\"Model Predict Time: \" , x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b70d6f-1a76-4272-8b8b-068a2261022c",
   "metadata": {},
   "source": [
    "# 5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18782e3f-a876-4615-9d66-61ae999be662",
   "metadata": {},
   "source": [
    "https://web.cs.hacettepe.edu.tr/~abc/teaching/bbm406/index.php\n",
    "\n",
    "https://stackoverflow.com\n",
    "\n",
    "https://theflyingmantis.medium.com/text-classification-in-nlp-naive-bayes-a606bf419f8c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
